{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from data_access import read_in_data, read_llm_output_data\n",
    "# api key:\n",
    "# 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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = pd.read_csv('../output/chat_gpt/output_chat_gpt.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_acc():\n",
    "    acc = []\n",
    "    for j in range(3,4):\n",
    "        for i in range(1,6):\n",
    "            path = '../data/foofah/exp0_'+str(j) + '_'+ str(i)+'_new'+ '.txt'\n",
    "            input_data, test_data = read_in_data(path)\n",
    "            output_data = read_llm_output_data('../output/Llama-2-7b-chat-hf/output_data_0_'+str(j) + '_'+ str(i)+ '.json')\n",
    "\n",
    "            #compare output_data and test_data\n",
    "            acc_temp = 0\n",
    "                # print(j,i)\n",
    "            for k in range(min(len(output_data),len(test_data[1]))):\n",
    "                for m in range(min(len(output_data[k]),len(test_data[1][k]))):\n",
    "                    if output_data[k][m] == test_data[1][k][m]:\n",
    "                        acc_temp += 1\n",
    "            acc.append(acc_temp/(len(test_data[1])*len(test_data[1][0])))\n",
    "    return(acc)\n",
    "                \n",
    "    \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.08333333333333333, 0.05, 0.0625, 0.0, 0.25]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = calculate_acc()\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Llama 7b chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.030612244897959183,\n",
       " 0.0989010989010989,\n",
       " 0.10714285714285714,\n",
       " 0.11688311688311688,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.005494505494505495,\n",
       " 0.44047619047619047,\n",
       " 0.38961038961038963,\n",
       " 0.38571428571428573,\n",
       " 0.044444444444444446,\n",
       " 0.0,\n",
       " 0.1111111111111111,\n",
       " 0.0,\n",
       " 0.2222222222222222,\n",
       " 0.03529411764705882,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.17647058823529413]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama2_7b_chat_acc = acc\n",
    "llama2_7b_chat_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2388125724260178"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(llama2_7b_chat_acc)/len(llama2_7b_chat_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat GPT Accuracy 3.5 turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.030612244897959183,\n",
       " 0.42857142857142855,\n",
       " 0.42857142857142855,\n",
       " 0.42857142857142855,\n",
       " 0.42857142857142855,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.03571428571428571,\n",
       " 0.18681318681318682,\n",
       " 0.13690476190476192,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.06666666666666667,\n",
       " 0.0,\n",
       " 0.3333333333333333,\n",
       " 0.0,\n",
       " 0.3333333333333333,\n",
       " 0.0,\n",
       " 0.058823529411764705,\n",
       " 0.11764705882352941,\n",
       " 0.11764705882352941,\n",
       " 0.11764705882352941]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_gpt_acc = acc\n",
    "chat_gpt_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34164760776105313"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(chat_gpt_acc)/len(chat_gpt_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy code and run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1093,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 51\n",
    "j = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### update i j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list = [\"craigslist_data_wrangler\", \"crime_data_wrangler\", \"potters_wheel_divide\", \"potters_wheel_fold\" ,\n",
    "                     \"potters_wheel_fold_2\", \"potters_wheel_merge_split\", \"potters_wheel_split_fold\", \"potters_wheel_unfold\", \n",
    "                     \"potters_wheel_unfold2\", \"proactive_wrangling_fold\", \"proactive_wrangling_complex\", \"reshape_table_structure_data_wrangler\"]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "j = 1\n",
    "i = name_list[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reshape_table_structure_data_wrangler 5\n"
     ]
    }
   ],
   "source": [
    "j += 1\n",
    "if j == 6:\n",
    "    j = 1\n",
    "    idx += 1\n",
    "    i = name_list[idx]\n",
    "print(i,j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_dataset(input_data):\n",
    "    output_data = [['', '1', '2', '3', '4', '5', '6']]\n",
    "    \n",
    "    years = set([data[0] for data in input_data])\n",
    "    years = sorted(list(years))\n",
    "    \n",
    "    for year in years:\n",
    "        temp = [year]\n",
    "        for i in range(1, 7):\n",
    "            value = [data[2] for data in input_data if data[0] == year and data[1] == str(i)]\n",
    "            if value:\n",
    "                temp.append(value[0])\n",
    "            else:\n",
    "                temp.append('')\n",
    "        output_data.append(temp)\n",
    "    \n",
    "    return output_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data to chatgpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/foofah/foofah/exp0_'+ str(i) + '_'+ str(j) + '.txt'\n",
    "input_data, test_data = read_in_data(path)\n",
    "r = transform_dataset(test_data[0])\n",
    "with open('../output/chat_gpt_3.5/foofah/new_output_data_0_'+str(i) + '_'+ str(j)+'.json', \"w\") as file: \n",
    "    json.dump(r, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/foofah/foofah/exp0_'+ str(i) + '_'+ str(j) + '.txt'\n",
    "input_data, test_data = read_in_data(path)\n",
    "with open('../output/chat_gpt_3.5/foofah/new_output_data_0_'+str(i) + '_'+ str(j)+'.json', \"w\") as file: \n",
    "    json.dump([[]], file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data to LLAma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii = 24\n",
    "jj = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 5\n"
     ]
    }
   ],
   "source": [
    "jj += 1\n",
    "if jj == 6:\n",
    "    jj = 1\n",
    "    ii += 1\n",
    "print(ii,jj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(input_data):\n",
    "    output_data = []\n",
    "    temp = []\n",
    "    \n",
    "    for item in input_data:\n",
    "        if item[0] != '':\n",
    "            if temp:\n",
    "                output_data.append(temp)\n",
    "            temp = [item[0]]\n",
    "        else:\n",
    "            temp.append(item[0])\n",
    "    \n",
    "    output_data.append(temp)\n",
    "    \n",
    "    return output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/foofah/foofah/exp0_'+ str(ii) + '_'+ str(jj) + '.txt'\n",
    "input_data, test_data = read_in_data(path)\n",
    "r = transform_data(test_data[0])\n",
    "with open('../output/Llama-2-7b-chat-hf/foofah/output_data_0_'+str(ii) + '_'+ str(jj)+'.json', \"w\") as file: \n",
    "    json.dump(r, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/foofah/foofah/exp0_'+ str(ii) + '_'+ str(jj) + '.txt'\n",
    "input_data, test_data = read_in_data(path)\n",
    "#r = transform_data(test_data[0])\n",
    "with open('../output/Llama-2-7b-chat-hf/foofah/output_data_0_'+str(ii) + '_'+ str(jj)+'.json', \"w\") as file: \n",
    "    json.dump([[]], file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACC save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../output/Llama-2-7b-chat-hf/accuracy.json', \"w\") as file: \n",
    "    json.dump(acc, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

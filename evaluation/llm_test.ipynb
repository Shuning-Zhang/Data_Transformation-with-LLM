{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from data_access import read_in_data, read_llm_output_data, read_output_data\n",
    "import pandas as pd\n",
    "import os\n",
    "import xlsxwriter\n",
    "# api key:\n",
    "# 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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list = [\"craigslist_data_wrangler\", \"crime_data_wrangler\", \"potters_wheel_divide\", \"potters_wheel_fold\" ,\n",
    "                     \"potters_wheel_fold_2\", \"potters_wheel_merge_split\", \"potters_wheel_split_fold\", \"potters_wheel_unfold\", \n",
    "                     \"potters_wheel_unfold2\", \"proactive_wrangling_fold\", \"proactive_wrangling_complex\", \"reshape_table_structure_data_wrangler\"]\n",
    "missing_list = [9, 14, 16, 20, 21, 23, 25, 31, 32, 35, 38, 39, 42,50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_acc():\n",
    "    acc = []\n",
    "    for j in name_list:\n",
    "\n",
    "        acc_1_5 = [0,0,0]\n",
    "        for i in range(1,6):\n",
    "            path = '../data/foofah/foofah/exp0_'+str(j) + '_'+ str(i)+ '.txt'\n",
    "            input_data, test_data = read_in_data(path)\n",
    "            gpt_3_5 = read_llm_output_data('../output/chat_gpt_3.5/foofah/new_output_data_0_'+str(j) + '_'+ str(i)+ '.json')\n",
    "            gpt_4_0 = read_llm_output_data('../output/chat_gpt_4.0/foofah/new_output_data_0_'+str(j) + '_'+ str(i)+ '.json')\n",
    "            if os.path.isfile('../output/foofah/foofah/exp0_results_'+str(j) + '_'+ str(i)+ '.txt'):\n",
    "                foofah = read_output_data('../output/foofah/foofah/exp0_results_'+str(j) + '_'+ str(i)+ '.txt')\n",
    "            else:\n",
    "                foofah = [[]]\n",
    "            for p, output_data in enumerate([gpt_3_5,gpt_4_0,foofah]):\n",
    "            #compare output_data and test_data\n",
    "                acc_temp = 0\n",
    "                    # print(j,i)\n",
    "                for k in range(min(len(output_data),len(test_data[1]))):\n",
    "                    for m in range(min(len(output_data[k]),len(test_data[1][k]))):\n",
    "                        if output_data[k][m] == test_data[1][k][m]:\n",
    "                            acc_temp += 1\n",
    "                acc_1_5[p] += (acc_temp/(len(test_data[1])*len(test_data[1][0])))/5\n",
    " \n",
    "\n",
    "        acc.append(acc_1_5)\n",
    "    return(acc)\n",
    "                \n",
    "    \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.5111111111111111, 0.7, 1.0],\n",
       " [0.0027506030781106767, 0.403921568627451, 0.20784313725490197],\n",
       " [0.37266955266955265, 0.6872727272727273, 0.8606060606060606],\n",
       " [0.8, 1.0, 0.0],\n",
       " [0.8500000000000001, 0.8666666666666667, 0.6000000000000001],\n",
       " [0.0, 0.8090909090909091, 0.909090909090909],\n",
       " [1.0, 0.8, 0.8666666666666667],\n",
       " [0.31222222222222223, 0.24666666666666665, 1.0],\n",
       " [0.7388888888888889, 0.7566666666666666, 1.0],\n",
       " [0.8466666666666667, 0.8, 1.0],\n",
       " [0.0, 0.15555555555555556, 1.0],\n",
       " [0.8666666666666667, 0.8309523809523809, 1.0]]"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = calculate_acc()\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(acc)\n",
    "df.to_excel('acc.xlsx')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Llama 7b chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.030612244897959183,\n",
       " 0.0989010989010989,\n",
       " 0.10714285714285714,\n",
       " 0.11688311688311688,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.005494505494505495,\n",
       " 0.44047619047619047,\n",
       " 0.38961038961038963,\n",
       " 0.38571428571428573,\n",
       " 0.044444444444444446,\n",
       " 0.0,\n",
       " 0.1111111111111111,\n",
       " 0.0,\n",
       " 0.2222222222222222,\n",
       " 0.03529411764705882,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.17647058823529413]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama2_7b_chat_acc = acc\n",
    "llama2_7b_chat_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2388125724260178"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(llama2_7b_chat_acc)/len(llama2_7b_chat_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat GPT Accuracy 3.5 turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.030612244897959183,\n",
       " 0.42857142857142855,\n",
       " 0.42857142857142855,\n",
       " 0.42857142857142855,\n",
       " 0.42857142857142855,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.03571428571428571,\n",
       " 0.18681318681318682,\n",
       " 0.13690476190476192,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.06666666666666667,\n",
       " 0.0,\n",
       " 0.3333333333333333,\n",
       " 0.0,\n",
       " 0.3333333333333333,\n",
       " 0.0,\n",
       " 0.058823529411764705,\n",
       " 0.11764705882352941,\n",
       " 0.11764705882352941,\n",
       " 0.11764705882352941]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_gpt_acc = acc\n",
    "chat_gpt_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34164760776105313"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(chat_gpt_acc)/len(chat_gpt_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy code and run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 'potters_wheel_unfold'\n",
    "j = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### update i j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list = [\"craigslist_data_wrangler\", \"crime_data_wrangler\", \"potters_wheel_divide\", \"potters_wheel_fold\" ,\n",
    "                     \"potters_wheel_fold_2\", \"potters_wheel_merge_split\", \"potters_wheel_split_fold\", \"potters_wheel_unfold\", \n",
    "                     \"potters_wheel_unfold2\", \"proactive_wrangling_fold\", \"proactive_wrangling_complex\", \"reshape_table_structure_data_wrangler\"]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "j = 0\n",
    "i = name_list[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reshape_table_structure_data_wrangler 5\n"
     ]
    }
   ],
   "source": [
    "j += 1\n",
    "if j == 6:\n",
    "    j = 1\n",
    "    idx += 1\n",
    "    i = name_list[idx]\n",
    "print(i,j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 1\n"
     ]
    }
   ],
   "source": [
    "j += 1\n",
    "if j == 6:\n",
    "    j = 1\n",
    "    i += 1\n",
    "print(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(input_data):\n",
    "    headers = ['']\n",
    "    students = []\n",
    "    student_data = {}\n",
    "\n",
    "    for data in input_data:\n",
    "        if data[1] not in headers:\n",
    "            headers.append(data[1])\n",
    "        if data[0] not in students:\n",
    "            students.append(data[0])\n",
    "            student_data[data[0]] = [''] * (len(headers) - 1)\n",
    "\n",
    "        student_data[data[0]][headers.index(data[1]) - 1] = data[2]\n",
    "\n",
    "    output_data = [headers]\n",
    "    for student in students:\n",
    "        output_data.append([student] + student_data[student])\n",
    "\n",
    "    return output_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data to chatgpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "potters_wheel_unfold 5\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[395], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/foofah/foofah/exp0_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(j) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      8\u001b[0m input_data, test_data \u001b[38;5;241m=\u001b[39m read_in_data(path)\n\u001b[0;32m----> 9\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mtransform_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../output/chat_gpt_4.0/foofah/new_output_data_0_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(j)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file: \n\u001b[1;32m     11\u001b[0m     json\u001b[38;5;241m.\u001b[39mdump(r, file)\n",
      "Cell \u001b[0;32mIn[394], line 13\u001b[0m, in \u001b[0;36mtransform_data\u001b[0;34m(input_data)\u001b[0m\n\u001b[1;32m     10\u001b[0m         students\u001b[38;5;241m.\u001b[39mappend(data[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     11\u001b[0m         student_data[data[\u001b[38;5;241m0\u001b[39m]] \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28mlen\u001b[39m(headers) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m     \u001b[43mstudent_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m     15\u001b[0m output_data \u001b[38;5;241m=\u001b[39m [headers]\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m student \u001b[38;5;129;01min\u001b[39;00m students:\n",
      "\u001b[0;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    }
   ],
   "source": [
    "# j += 1\n",
    "# if j == 6:\n",
    "#     j = 1\n",
    "#     idx += 1\n",
    "#     i = name_list[idx]\n",
    "print(i,j)\n",
    "path = '../data/foofah/foofah/exp0_'+ str(i) + '_'+ str(j) + '.txt'\n",
    "input_data, test_data = read_in_data(path)\n",
    "r = transform_data(test_data[0])\n",
    "with open('../output/chat_gpt_4.0/foofah/new_output_data_0_'+str(i) + '_'+ str(j)+'.json', \"w\") as file: \n",
    "    json.dump(r, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/foofah/foofah/exp0_'+ str(i) + '_'+ str(j) + '.txt'\n",
    "input_data, test_data = read_in_data(path)\n",
    "with open('../output/chat_gpt_4.0/foofah/new_output_data_0_'+str(i) + '_'+ str(j)+'.json', \"w\") as file: \n",
    "    json.dump([[]], file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data to LLAma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii = 24\n",
    "jj = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 5\n"
     ]
    }
   ],
   "source": [
    "jj += 1\n",
    "if jj == 6:\n",
    "    jj = 1\n",
    "    ii += 1\n",
    "print(ii,jj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(input_data):\n",
    "    output_data = []\n",
    "    temp = []\n",
    "    \n",
    "    for item in input_data:\n",
    "        if item[0] != '':\n",
    "            if temp:\n",
    "                output_data.append(temp)\n",
    "            temp = [item[0]]\n",
    "        else:\n",
    "            temp.append(item[0])\n",
    "    \n",
    "    output_data.append(temp)\n",
    "    \n",
    "    return output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/foofah/foofah/exp0_'+ str(ii) + '_'+ str(jj) + '.txt'\n",
    "input_data, test_data = read_in_data(path)\n",
    "r = transform_data(test_data[0])\n",
    "with open('../output/Llama-2-7b-chat-hf/foofah/output_data_0_'+str(ii) + '_'+ str(jj)+'.json', \"w\") as file: \n",
    "    json.dump(r, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/foofah/foofah/exp0_'+ str(ii) + '_'+ str(jj) + '.txt'\n",
    "input_data, test_data = read_in_data(path)\n",
    "#r = transform_data(test_data[0])\n",
    "with open('../output/Llama-2-7b-chat-hf/foofah/output_data_0_'+str(ii) + '_'+ str(jj)+'.json', \"w\") as file: \n",
    "    json.dump([[]], file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACC save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../output/Llama-2-7b-chat-hf/accuracy.json', \"w\") as file: \n",
    "    json.dump(acc, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
